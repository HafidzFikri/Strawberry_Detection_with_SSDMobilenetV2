{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n- import objec\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset Preparation\n",
    "\"\"\"\n",
    "- get the image from internet or public dataset like roboflow etc\n",
    "- annotate every images to get their object which strawberry in every images and save in csv or txt file\n",
    "    - for my case, i took format annotate as [ filename, width_image, height_image, class_object, xmin, ymin, xmax, ymax]\n",
    "    - convert csv or txt with annotated images and images to tfrecord format\n",
    "\"\"\"\n",
    "# Processing which modelling, training, save model, for optional convert to tflite with or without quantized\n",
    "\"\"\"\n",
    "- import objec\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "error: RPC failed; curl 92 HTTP/2 stream 5 was not closed cleanly: CANCEL (err 8)\n",
      "error: 6489 bytes of body are still expected\n",
      "fetch-pack: unexpected disconnect while reading sideband packet\n",
      "fatal: early EOF\n",
      "fatal: fetch-pack: invalid index-pack output\n"
     ]
    }
   ],
   "source": [
    "# get tensorflow object_detection API \n",
    "!git clone --depth 1 https://github.com/tensorflow/models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For compatibility. Pin tf-models-official version so it will use Tensorflow 2.15.\n",
    "\n",
    "!sed -i 's/tf-models-official>=2.5.1/tf-models-official==2.15.0/g' ./models/research/object_detection/packages/tf2/setup.py\n",
    "\n",
    "# Compile the Object Detection API protocol buffers and install the necessary packages which in setup.py\n",
    "!cd models/research/ && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hafid\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import object_detection\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from object_detection.utils import config_util, label_map_util, dataset_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i use python 3.10 and compatible too for 3.11 for this case\n",
    "# tensorflow 2.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust to yout needs\n",
    "model_dir = '/content/my_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pretarined model SSDMobilenetV2FPNLite with input shape imgae 320x320\n",
    "!wget -- 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "\n",
    "# move model to yout directory and tar it, i use G.colab and move it in 'sample_data' dir. \n",
    "!mv ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz {'sample_data'}\n",
    "!cd {'sample_data'} && tar -zxvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy pipeline.config to your model dir\n",
    "!cp /content/sample_data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config /content/my_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the config\n",
    "config_path = '/content/my_model/pipeline.config'\n",
    "configs = config_util.get_configs_from_pipeline_file(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can manually adjust the config with open them, in this i use code for adjuts a little bit\n",
    "\"\"\"\n",
    "- num classes from 90 to 3 for my case strawberry ripe [ripe, half ripe, not ripe]\n",
    "- checkpoint type into detection\n",
    "- set checkpoint to pretrained model checkpoint\n",
    "- and set my dataset which train, valid and label\n",
    "\"\"\"\n",
    "\n",
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(config_path, \"r\") as f:\n",
    "    proto_str = f.read()\n",
    "    text_format.Merge(proto_str, pipeline_config)\n",
    "\n",
    "pipeline_config.model.ssd.num_classes = 3\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint ='/content/sample_data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0'\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= '/content/my_model/label.pbtxt'\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = ['/content/my_model/Train.tfrecord']\n",
    "pipeline_config.eval_input_reader[0].label_map_path = '/content/my_model/label.pbtxt'\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = ['/content/my_model/Valid.tfrecord']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check pipeline\n",
    "pipeline_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set config\n",
    "config_text = text_format.MessageToString(pipeline_config)\n",
    "with tf.io.gfile.GFile(config_path, \"wb\") as f:\n",
    "    f.write(config_text)\n",
    "configs = config_util.get_configs_from_pipeline_file(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for my case which use tensorflow 2.15, some code in decoder.py needs to be changed\n",
    "\n",
    "# Path to file tfexample_decoder.py\n",
    "dirr_pack = '/usr/local/lib/python3.10/dist-packages'\n",
    "file_path = f\"{dirr_pack}/tf_slim/data/tfexample_decoder.py\"\n",
    "\n",
    "\n",
    "# Membaca dan memodifikasi file\n",
    "with open(file_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Memodifikasi konten file\n",
    "with open(file_path, 'w') as f:\n",
    "    for i, line in enumerate(lines):\n",
    "        if i == 27:\n",
    "            f.write(\"import tensorflow as tf\\n\")\n",
    "        \n",
    "        if \"control_flow_ops.case\" in line:\n",
    "            line = line.replace(\"control_flow_ops.case\", \"tf.case\")\n",
    "        f.write(line)\n",
    "\n",
    "        if \"control_flow_ops.cond\" in line:\n",
    "            line = line.replace(\"control_flow_ops.cond\", \"tf.cond\")\n",
    "        f.write(line)\n",
    "\n",
    "print(\"finish\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'c:\\\\content\\\\models\\\\research\\\\object_detection\\\\model_main_tf2.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# train model with model_main_tf2.py\n",
    "\"\"\"\n",
    "- set pipeline config to your pipeline.config.file\n",
    "- set model_dir to your model directory, the checkpoint, train info, and train result would be in there\n",
    "- set num train, in my case i set to 20,000 times instead of 50,000 for default\n",
    "\"\"\"\n",
    "\n",
    "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path=/content/my_model/pipeline.config\\\n",
    "    --model_dir=/content/my_model \\\n",
    "    --num_train_steps=20000 \\\n",
    "    --sample_1_of_n_eval_examples=1 \\\n",
    "    --alsologtostderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x000001CC876A2350>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x000001CC876A2350>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.predictors.convolutional_keras_box_predictor.WeightSharedConvolutionalBoxPredictor object at 0x000001CC876A32D0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.predictors.convolutional_keras_box_predictor.WeightSharedConvolutionalBoxPredictor object at 0x000001CC876A32D0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.models.ssd_mobilenet_v2_fpn_keras_feature_extractor.SSDMobileNetV2FpnKerasFeatureExtractor object at 0x000001CC83ED8990>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.models.ssd_mobilenet_v2_fpn_keras_feature_extractor.SSDMobileNetV2FpnKerasFeatureExtractor object at 0x000001CC83ED8990>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.predictors.heads.keras_box_head.WeightSharedConvolutionalBoxHead object at 0x000001CC87696C90>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.predictors.heads.keras_box_head.WeightSharedConvolutionalBoxHead object at 0x000001CC87696C90>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.predictors.heads.keras_class_head.WeightSharedConvolutionalClassHead object at 0x000001CC87697810>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.predictors.heads.keras_class_head.WeightSharedConvolutionalClassHead object at 0x000001CC87697810>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x000001CC87697CD0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x000001CC87697CD0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x000001CC876A3C90>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x000001CC876A3C90>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/1/assets\n"
     ]
    }
   ],
   "source": [
    "# Path to the checkpoint directory\n",
    "checkpoint_dir = '/content/my_model'\n",
    "configs = config_util.get_configs_from_pipeline_file(f'{checkpoint_dir}/pipeline.config')\n",
    "\n",
    "# Load pipeline config and build detection model\n",
    "\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(f'{checkpoint_dir}/ckpt-21').expect_partial()\n",
    "\n",
    "export = 'model/1/'\n",
    "tf.saved_model.save(detection_model, export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hafid\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\converters\\directives.py:126: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hafid\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\converters\\directives.py:126: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hafid\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\converters\\directives.py:126: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hafid\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\converters\\directives.py:126: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hafid\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hafid\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'app' from 'c:\\\\Users\\\\hafid\\\\Downloads\\\\Strawberry_Detection_with_SSDMobilenetV2\\\\app.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import app\n",
    "app\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
